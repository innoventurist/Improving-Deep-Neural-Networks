<h1><strong> Improving Deep Neural Networks </strong></h1>

![Deep Learning](https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fspecials-images.forbesimg.com%2Fimageserve%2F1132912604%2F0x0.jpg%3FcropX1%3D0%26cropX2%3D3840%26cropY1%3D0%26cropY2%3D2160)

<h2><strong><em> About </em></strong></h2>

<p>Deep Learning, also referred to as Neural Networks, can be implemented into various types of applications such as real estate, online advertising, image, audio,
 machine translation and autonomous driving. Methods and architectures used in these industries include convolutional neural networks (CNN), recurrent neural
 networks (RNN), long short term memory (LSTM), dropout, batch norm, etc. Overall, the goal is for AI to be as close to the capabilities of a human based off
 the workings of the brain. </p>

<p>This section specifically looks at improving deep NNs using hyperparameter tuning, regularization and optimization. This could also be done using dropout, etc.,
and other optimization algorithms like mini-batch gradient descent (GD), RMSprop and Adam. All implementations were done using tensorflow. </p>

<h2><p><strong><em>Projects:</em></strong></p></h2>

<ul>
<li>Practical Aspects of Deep Learning</li>
<li>Optimization Algorithms</li>
<li>Hyperparameter Tuning, Batch Normalization and Programming Frameworks</li>
</ul>

![Deep Neural Network](https://tectales.com/media/story_section_image/529/img-01-rsna-ai-adhd.png)
<h2><p><strong><em>Goal:</em></strong></p></h2>

<p>Understand the best practices and tricks when dealing with issues that may happen with deep architectures. Learning how to set up a train/test/dev set and
analyze bias and variance. Overall, the goal is to help in driving performance with minimal amount of error.</p>
